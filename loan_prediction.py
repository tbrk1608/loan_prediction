# -*- coding: utf-8 -*-
"""loan_prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YwqvZaRoSSnjPqW_K07QcIyjrvepcgc6
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_validate, cross_val_score, KFold
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from math import sqrt

# # Run at every new runtime/session
# from google.colab import drive
# drive.mount('/content/drive',force_remount=True)

train_data = "/content/drive/MyDrive/ML/loan_prediction/loan_prediction_train.csv"
test_data = "/content/drive/MyDrive/ML/loan_prediction/loan_prediction_test.csv"

train_data_set = pd.read_csv(train_data)
test_data_set = pd.read_csv(test_data)

sub_col1 = test_data_set['Loan_ID']

train_data_set.head()

test_data_set.head()

train_data_set.describe()

print(train_data_set.info())
print(test_data_set.info())

continous_variable = ["ApplicantIncome","CoapplicantIncome","LoanAmount","Loan_Amount_Term"]
target_variable = "Loan_Status"
unwanted = ['Loan_ID']
categorical_variable = list(set(train_data_set.columns)-set(continous_variable+[target_variable]+unwanted))

#missing values and dups check
print("Missing values check:")
print("In Train\n",train_data_set.isnull().sum(),'\n')
print("In Test\n",test_data_set.isnull().sum(),'\n')

print("Duplicate values check in Train:")
if len(train_data_set[train_data_set.duplicated()]) > 0:
    print("Number of duplicated entries {}".format(len(train_data_set[train_data_set.duplicated()])))
    print(train_data_set[train_data_set.duplicated()])
else:
    print("No duplicated entries found")

#removing dups
if len(train_data_set[train_data_set.duplicated()]) > 0:
  print("Dropping Duplicates")
  train_data_set = train_data_set.drop_duplicates()
  print("{} duplicates now".format(len(train_data_set[train_data_set.duplicated()])))

#value_counts in each categorical column
subplots_count = len(categorical_variable)
fig = plt.figure(figsize=(25,40))
fig.subplots_adjust(hspace=0.5)
for v,col in enumerate(categorical_variable):
  print("Missing Count",train_data_set[col].isnull().sum(),'\n')
  print(train_data_set[col].value_counts(),'\n')
  v+=1
  axs = fig.add_subplot(subplots_count,2,v)
  sns.countplot(x=col,data=train_data_set)
plt.show()

for cv in categorical_variable:
  train_data_set[cv] = train_data_set[cv].fillna(train_data_set[cv].mode()[0])
train_data_set['Loan_Amount_Term'] = train_data_set['Loan_Amount_Term'].fillna(train_data_set['Loan_Amount_Term'].mode()[0])
train_data_set['LoanAmount'] = train_data_set['LoanAmount'].fillna(train_data_set['LoanAmount'].mean())

for cv in categorical_variable:
  test_data_set[cv] = test_data_set[cv].fillna(test_data_set[cv].mode()[0])
test_data_set['Loan_Amount_Term'] = test_data_set['Loan_Amount_Term'].fillna(test_data_set['Loan_Amount_Term'].mode()[0])
test_data_set['LoanAmount'] = test_data_set['LoanAmount'].fillna(test_data_set['LoanAmount'].mean())

print("In Train\n",train_data_set.isnull().sum(),'\n')
print("In Test\n",test_data_set.isnull().sum(),'\n')

print("Value Counts:",train_data_set[target_variable].value_counts(),sep='\n')
sns.countplot(x=train_data_set[target_variable])

sns.pairplot(data = train_data_set[continous_variable])

subplots_count = len(categorical_variable)

fig = plt.figure(figsize=(20,20))
fig.subplots_adjust(hspace=0.5)
for v,col in enumerate(categorical_variable):
  v+=1
  axs = fig.add_subplot(subplots_count,4,v)
  sns.countplot(x=col,data=train_data_set[categorical_variable])
plt.show()

fig = plt.figure(figsize=(15,20))
fig.subplots_adjust(hspace=0.5)
subplots_count = len(continous_variable)
for v,col in enumerate(continous_variable):
  v+=1
  axs = fig.add_subplot(subplots_count,2,v)
  sns.distplot(train_data_set[continous_variable][col],ax=axs,hist=True, kde=True)
plt.show()

def emi_cal(p,r,n):
  p=p*1000
  r=r/(12*100)
  emi = (p*r*pow(1+r,n))/(pow(1+r,n)-1) 
  return round(emi,2)

train_data_set['TotalIncome'] = train_data_set['ApplicantIncome'] + train_data_set['CoapplicantIncome']
train_data_set = train_data_set.drop(['ApplicantIncome','CoapplicantIncome'],axis=1)
   
train_data_set['Monthly_Payment'] = train_data_set.apply(lambda x: emi_cal(x['LoanAmount'],9,x['Loan_Amount_Term']),axis=1)
train_data_set['Income_Final'] = train_data_set['TotalIncome'] - train_data_set['Monthly_Payment']
train_data_set = train_data_set.drop(["LoanAmount","Loan_Amount_Term"],axis=1)


test_data_set['TotalIncome'] = test_data_set['ApplicantIncome'] + test_data_set['CoapplicantIncome']
test_data_set = test_data_set.drop(['ApplicantIncome','CoapplicantIncome'],axis=1)
test_data_set['Monthly_Payment'] = test_data_set.apply(lambda x: emi_cal(x['LoanAmount'],9,x['Loan_Amount_Term']),axis=1)
test_data_set['Income_Final'] = test_data_set['TotalIncome'] - test_data_set['Monthly_Payment']
test_data_set = test_data_set.drop(["LoanAmount","Loan_Amount_Term"],axis=1)

train_data_set['TotalIncome'] = np.log(train_data_set['TotalIncome'])
train_data_set['Monthly_Payment'] = np.log(train_data_set['Monthly_Payment'])
train_data_set['Income_Final'] = np.log(train_data_set['Income_Final'])

test_data_set['TotalIncome'] = np.log(test_data_set['TotalIncome'])
test_data_set['Monthly_Payment'] = np.log(test_data_set['Monthly_Payment'])
test_data_set['Income_Final'] = np.log(test_data_set['Income_Final'])

fig = plt.figure(figsize=(15,20))
fig.subplots_adjust(hspace=0.5)
for v,col in enumerate(["TotalIncome","Monthly_Payment","Income_Final"]):
  v+=1
  axs = fig.add_subplot(3,2,v)
  sns.distplot(train_data_set[col],ax=axs,hist=True, kde=True)
plt.show()

train_data_set=train_data_set.drop(unwanted,axis=1)
test_data_set = test_data_set.drop(unwanted,axis=1)

train_data_set.head()

test_data_set.head()

train_data_set['Loan_Status']=train_data_set['Loan_Status'].map({"Y":1,"N":0})
train_dummied=pd.get_dummies(data = train_data_set, columns=categorical_variable, prefix=categorical_variable,prefix_sep= "_")

test_dummied=pd.get_dummies(data = test_data_set, columns=categorical_variable, prefix=categorical_variable,prefix_sep= "_")

train_dummied = train_dummied.fillna(0)

train_dummied.isnull().sum()

test_dummied = test_dummied.fillna(0)

test_dummied.isnull().sum()

y_train = train_dummied[target_variable]
x_train = train_dummied.drop(target_variable,axis=1)

lr_model = LogisticRegression(max_iter=200)

kfold=KFold(n_splits=10,shuffle=True,random_state=8) 
acc=cross_val_score(lr_model,x_train,y_train,scoring='accuracy',cv=kfold)
print('accuracy : {}'.format(acc.mean()))

lr_model.fit(x_train,y_train)
test_pred = lr_model.predict(test_dummied)

sub_df = pd.DataFrame()
sub_df['Loan_ID'] = sub_col1
sub_df['Loan_Status'] = test_pred
sub_df['Loan_Status'] = sub_df['Loan_Status'].replace({1:'Y',0:'N'})
sub_df.head()

sub_df.to_csv('loan_prediction_submission.csv',index=False)
# !cp loan_prediction_submission.csv "drive/My Drive/"

